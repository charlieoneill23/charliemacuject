{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "114075c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report, accuracy_score, confusion_matrix\n",
    "from scipy.special import expit\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from fastbook import *\n",
    "from pandas.api.types import is_string_dtype, is_numeric_dtype, is_categorical_dtype\n",
    "from fastai.tabular.all import *\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from dtreeviz.trees import *\n",
    "from IPython.display import Image, display_svg, SVG\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333732cb",
   "metadata": {},
   "source": [
    "# Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "30c25835",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('/home/jupyter/charliemacuject/research_papers/dme/input/df_train_one.csv')\n",
    "df_train.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "df_test = pd.read_csv('/home/jupyter/charliemacuject/research_papers/dme/input/df_test_one.csv')\n",
    "df_test.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dd0110ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df_train.drop(columns=['outcome', 'id'])\n",
    "y_train = df_train.outcome\n",
    "X_test = df_test.drop(columns=['outcome', 'id'])\n",
    "y_test = df_test.outcome"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8750546",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, pd.get_dummies(X_train.location)], axis=1)\n",
    "X_train.drop(columns=['location'], inplace=True)\n",
    "X_test = pd.concat([X_test, pd.get_dummies(X_test.location)], axis=1)\n",
    "X_test.drop(columns=['location'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1f74bfff",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.concat([X_train, pd.get_dummies(X_train.initiation_drug)], axis=1)\n",
    "X_train.drop(columns=['initiation_drug'], inplace=True)\n",
    "X_test = pd.concat([X_test, pd.get_dummies(X_test.initiation_drug)], axis=1)\n",
    "X_test.drop(columns=['initiation_drug'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a950a9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_vision', 'std_vision', 'peak_visual_improvement', 'baseline',\n",
       "       'boronia', 'box_hill', 'Avastin', 'Eylea', 'IVTA', 'Lucentis',\n",
       "       'No Injection', 'Ozurdex'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e031e850",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['mean_vision', 'std_vision', 'peak_visual_improvement', 'baseline',\n",
       "       'boronia', 'box_hill', 'Avastin', 'Eylea', 'Lucentis', 'No Injection',\n",
       "       'Ozurdex'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f034089b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_test['Ozurdex'] = 0\n",
    "X_test['IVTA'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5837eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_true, y_pred):\n",
    "    correct_counter = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == yp:\n",
    "            correct_counter += 1\n",
    "    return round(correct_counter / len(y_true), 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e8e1b848",
   "metadata": {},
   "outputs": [],
   "source": [
    "def m_accuracy(m, X, y): \n",
    "    return accuracy(m.predict(X), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "02277c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf(xs, y, n_estimators=100, max_samples=28,\n",
    "       max_features=0.5, min_samples_leaf=5, random_state=42, **kwargs):\n",
    "    return RandomForestClassifier(n_jobs=-1, n_estimators=n_estimators,\n",
    "        max_samples=max_samples, max_features=max_features, random_state=42,\n",
    "        min_samples_leaf=min_samples_leaf, oob_score=True, warm_start=True).fit(xs, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "45e2e252",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.68333, 0.87234)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = rf(X_train, y_train)\n",
    "m_accuracy(m, X_train, y_train), m_accuracy(m, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e006a6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 47)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train), len(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "688d0873",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae05b826",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import metrics \n",
    "\n",
    "l1 = [0,1,1,1,0,0,0,1]\n",
    "l2 = [0,1,0,1,0,1,0,0]\n",
    "metrics.accuracy_score(l1, l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8e8d19a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    28\n",
       "1    19\n",
       "Name: outcome, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19a660e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5957446808510638"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "28 / (28 + 19)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adbfad51",
   "metadata": {},
   "source": [
    "Thus, if we instantiated a model that just predicted a negative OVC, we would have 58%. The distribution of labels is fairly even.\n",
    "\n",
    "Before learning about precision, we need to define a few terms. Here, we assume that patients with positive OVC are in the positive class (1) and with negative OVC are in the negative class (0).\n",
    "* __True positive__ (TP): given a patient, if the model predicts they have a positive OVC, and the actual target is 1, is is considered a true positive.\n",
    "* __True negative__ (TN): given a patient, if the model predicts they have a negative OVC, and the actual target is 0, is is considered a true negative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cb856d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def true_positive(y_true, y_pred):\n",
    "    tp = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 1 and yp == 1:\n",
    "            tp += 1\n",
    "    return tp\n",
    "\n",
    "def true_negative(y_true, y_pred):\n",
    "    tn = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 0 and yp == 0:\n",
    "            tn += 1\n",
    "    return tn\n",
    "\n",
    "def false_positive(y_true, y_pred):\n",
    "    fp = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 0 and yp == 1:\n",
    "            fp += 1\n",
    "    return fp\n",
    "\n",
    "def false_negative(y_true, y_pred):\n",
    "    fn = 0\n",
    "    for yt, yp in zip(y_true, y_pred):\n",
    "        if yt == 1 and yp == 0:\n",
    "            fn += 1\n",
    "    return fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fed376e0",
   "metadata": {},
   "source": [
    "We can now re-implement accuracy score using these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3ed1ca79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy_v2(y_true, y_pred):\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    fn = false_negative(y_true, y_pred)\n",
    "    tn = true_negative(y_true, y_pred)\n",
    "    return (tp + tn) / (tp + tn + fp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "97b9859d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.625"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_v2(l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c26e743c",
   "metadata": {},
   "source": [
    "_Precision_ is defined as $TP / (TP + FP)$. Let's say we make a new model on the slightly skewed dataset, and our model correctly identifies 80 negative OVCs out of 90 and 8 positive OVCs out of 10. Thus, we identify 88 out of 100 patients correctly. Accuracy is thus 88%.\n",
    "\n",
    "However, out of these 100 patients, 10 negative OVCs are misclassified as positive and 2 negatives are misclassified as positive. Thus, $TP=8, TN=80, FP=10, FN=2$. So precision is $8/(8+10)=0.444$. This means our model is correct 44.4% of the time when trying to identify positive OVCs.\n",
    "\n",
    "Think of precision as being the percentage of correctly predicted positive cases out of the total predicted positive cases. That is, of our patients we predicted were OVC positive, how many actually were?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "51429fcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def precision(y_true, y_pred):\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    return tp / (tp + fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "cb8aa17c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "precision(l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d36948",
   "metadata": {},
   "source": [
    "_Recall_ is defined as $TP / (TP + FN)$. In the above case recall is $8/(8+2)=0.80$. Recall thus calculates how many of the actual positive OVCs our model picks up on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bf71cbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(y_true, y_pred):\n",
    "    tp = true_positive(y_true, y_pred)\n",
    "    fn = false_negative(y_true, y_pred)\n",
    "    return tp / (tp + fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1ba2f6dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "137e512f",
   "metadata": {},
   "source": [
    "It's challenging to choose a value of threshold that gives both good precision and recall values. If the threshold for cutoff is too high, you end up with a smaller number of true positives and a high number of false negatives. This decreases the recall; however, the precision will be high. If the treshold is too low, false positives will increase, and precision will be less.\n",
    "\n",
    "_F1 score_ is a metric that combines both precision and recall. It is defined as a simple weighted average (harmonic mean) of precision and recall. If we denote precision using P and recall using R, we can represent the F1 score as $F1 = 2PR / (P + R)$. Rearranging, we obtain $F1 = 2TP / (2TP + FP + FN)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a2d60972",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1(y_true, y_pred):\n",
    "    p = precision(y_true, y_pred)\n",
    "    r = recall(y_true, y_pred)\n",
    "    score = 2* p * r / (p + r)\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "90bd8978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5714285714285715"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1(l1, l2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6341b968",
   "metadata": {},
   "source": [
    "True positive rate is the same as recall, and is also known as _sensitivity_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e6720eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tpr(y_true, y_pred):\n",
    "    return recall(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3b0181f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fpr(y_true, y_pred):\n",
    "    fp = false_positive(y_true, y_pred)\n",
    "    tn = true_negative(y_true, y_pred)\n",
    "    return fp / (tn + fp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f43781a",
   "metadata": {},
   "source": [
    "## Automating metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "fc16a6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "\n",
    "def model_evaluation(model, X, y_true):\n",
    "    y_pred = model.predict(X)\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    df = pd.DataFrame({'Accuracy': [accuracy], 'F1_Score': [f1],\n",
    "                       'Precision': [precision], 'Recall': [recall]})\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c3e247fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1_Score</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.87234</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.809524</td>\n",
       "      <td>0.894737</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Accuracy  F1_Score  Precision    Recall\n",
       "0   0.87234      0.85   0.809524  0.894737"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_evaluation(m, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046c6fc4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "common-cu110.m74",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cu110:m74"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
